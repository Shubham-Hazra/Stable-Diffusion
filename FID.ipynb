{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import logging\n",
    "from torch import tensor\n",
    "import numpy as np\n",
    "import torchvision \n",
    "import random,math\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from operator import attrgetter\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader,default_collate,Dataset\n",
    "from copy import copy\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from collections.abc import Mapping\n",
    "from diffusers import UNet2DModel\n",
    "from tqdm import tqdm\n",
    "from diffusers import DDIMScheduler, DDPMScheduler, LMSDiscreteScheduler, PNDMScheduler, EulerAncestralDiscreteScheduler\n",
    "from scipy import linalg\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from pytorch_fid.inception import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the device\n",
    "def_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# Function to send data to device\n",
    "def to_device(x, device=def_device):\n",
    "    if isinstance(x, torch.Tensor): return x.to(device)\n",
    "    if isinstance(x, Mapping): return {k:v.to(device) for k,v in x.items()}\n",
    "    return type(x)(to_device(o, device) for o in x)\n",
    "\n",
    "def to_cpu(x):\n",
    "    if isinstance(x, Mapping): return {k:to_cpu(v) for k,v in x.items()}\n",
    "    if isinstance(x, list): return [to_cpu(o) for o in x]\n",
    "    if isinstance(x, tuple): return tuple(to_cpu(list(x)))\n",
    "    res = x.detach().cpu()\n",
    "    return res.float() if res.dtype==torch.float16 else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "# Remember to pad the images with 2 pixels on each side i.e. to make the image size 32x32\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "transforms = T.Compose([T.ToTensor(),T.Pad(2)])\n",
    "\n",
    "train_ds = torchvision.datasets.FashionMNIST(root = './data/train',train = True,download = True,transform = transforms)\n",
    "valid_ds = torchvision.datasets.FashionMNIST(root = './data/valid',train = False,download = True,transform = transforms)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "class DDPM_model(nn.Module):\n",
    "    def __init__(self, model, beta_min = 0.0001, beta_max = 0.02, n_steps = 1000, cosine_schedule = False):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.beta_min = beta_min\n",
    "        self.beta_max = beta_max\n",
    "        self.n_steps = n_steps\n",
    "        if cosine_schedule:\n",
    "            def abar(t, T): return (t/T*math.pi/2).cos()**2\n",
    "            timesteps = torch.linspace(0, self.n_steps -1 , self.n_steps)\n",
    "            self.alphabar = abar(timesteps, self.n_steps)\n",
    "            self.alpha = self.alphabar/abar(timesteps-1, self.n_steps)\n",
    "            self.beta = 1 - self.alpha\n",
    "            self.sigma = self.beta.sqrt()\n",
    "        else:\n",
    "            self.beta = torch.linspace(beta_min, beta_max, self.n_steps)\n",
    "            self.alpha = 1. - self.beta\n",
    "            self.alphabar = self.alpha.cumprod(dim=0)\n",
    "            self.sigma = self.beta.sqrt()\n",
    "\n",
    "    def add_noise(self, x_0):\n",
    "        device = x_0.device\n",
    "        n = len(x_0)\n",
    "        timesteps = torch.randint(0, self.n_steps, (n,), device=device)\n",
    "        alphabar_t = self.alphabar.to(device)[timesteps].reshape(-1, 1, 1, 1)\n",
    "        noise = torch.randn_like(x_0, device=device)\n",
    "        x_t = x_0 * alphabar_t.sqrt() + (1. - alphabar_t).sqrt()* noise\n",
    "        return (x_t, timesteps.to(device)), noise\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model.forward(*x).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# Take in a scheduler and sample from the model using the scheduler\n",
    "\n",
    "def sample(sched,model,sz = (16,3,32,32)):\n",
    "    preds = []\n",
    "    device = next(model.parameters()).device\n",
    "    x_t = torch.randn(sz).to(device)\n",
    "    for t in tqdm(sched.timesteps,total=len(sched.timesteps)):\n",
    "        with torch.no_grad(): noise = model((x_t, t))\n",
    "        x_t = sched.step(noise, t, x_t).prev_sample\n",
    "        preds.append(x_t.float().cpu())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to calculate the inception score\n",
    "\n",
    "def calc_stats(feats):\n",
    "    feats = feats.squeeze()\n",
    "    return feats.mean(0),feats.T.cov()\n",
    "\n",
    "def calc_fid(m1,c1,m2,c2):\n",
    "    csr = tensor(linalg.sqrtm(c1@c2, 256).real)\n",
    "    return (((m1-m2)**2).sum() + c1.trace() + c2.trace() - 2*csr.trace()).item()\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = InceptionV3(resize_input=True)\n",
    "    def forward(self, x): return self.model(x.repeat(1,3,1,1))[0]\n",
    "\n",
    "def get_fid(real_batch, fake_batch, device=def_device, model=Inception().to(def_device)):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        real_feats = model(to_device(real_batch, device))\n",
    "        fake_feats = model(to_device(fake_batch, device))\n",
    "        real_feats = to_cpu(real_feats)\n",
    "        fake_feats = to_cpu(fake_feats)\n",
    "        m1,c1 = calc_stats(real_feats)\n",
    "        m2,c2 = calc_stats(fake_feats)\n",
    "        return calc_fid(m1,c1,m2,c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102.07628140364267\n"
     ]
    }
   ],
   "source": [
    "# Get FID for two batches of real images\n",
    "\n",
    "it = iter(train_dl)\n",
    "real_batch,_ = next(it)\n",
    "real_batch_2,_ = next(it)\n",
    "\n",
    "fid = get_fid(real_batch, real_batch_2)\n",
    "print(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "\n",
    "unet_model = UNet2DModel(in_channels=1, out_channels=1, block_out_channels=(32, 64, 128, 128),norm_num_groups=8)\n",
    "model = DDPM_model(unet_model, 0.0001, 0.02, 1000, cosine_schedule=False)\n",
    "model.load_state_dict(torch.load(\"DDPM_state_dict.pth\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [08:39<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187.42056070609073\n"
     ]
    }
   ],
   "source": [
    "# Get FID using DDPM scheduler for 1000 timesteps\n",
    "\n",
    "sched = DDPMScheduler(beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
    "preds = sample(sched,model,(64,1,32,32))\n",
    "fid = get_fid(real_batch, preds[-1])\n",
    "print(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341.5343243573738\n"
     ]
    }
   ],
   "source": [
    "# Get FID using DDIM scheduler for 500 timesteps\n",
    "\n",
    "sched = DDIMScheduler(beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
    "sched.set_timesteps(500)\n",
    "preds = sample(sched,model,(64,1,32,32))\n",
    "\n",
    "\n",
    "fid = get_fid(real_batch, preds[-1])\n",
    "print(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 333/333 [03:03<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350.20018457582114\n"
     ]
    }
   ],
   "source": [
    "# Get FID using DDIM scheduler for 333 timesteps\n",
    "\n",
    "sched = DDIMScheduler(beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
    "sched.set_timesteps(333)\n",
    "preds = sample(sched,model,(64,1,32,32))\n",
    "\n",
    "\n",
    "fid = get_fid(real_batch, preds[-1])\n",
    "print(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:27<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315.70180505655634\n"
     ]
    }
   ],
   "source": [
    "# Get FID using DDIM scheduler for 50 timesteps\n",
    "\n",
    "sched = DDIMScheduler(beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
    "sched.set_timesteps(50)\n",
    "preds = sample(sched,model,(64,1,32,32))\n",
    "\n",
    "\n",
    "fid = get_fid(real_batch, preds[-1])\n",
    "print(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:33<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288.7396716038522\n"
     ]
    }
   ],
   "source": [
    "# Get FID using PNDM scheduler for 50 timesteps\n",
    "\n",
    "sched = PNDMScheduler(beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
    "sched.set_timesteps(50)\n",
    "preds = sample(sched,model,(64,1,32,32))\n",
    "\n",
    "\n",
    "fid = get_fid(real_batch, preds[-1])\n",
    "print(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "# Remember to pad the images with 2 pixels on each side i.e. to make the image size 32x32\n",
    "# There is an extra normalization transform here to make the images between -0.5 and 0.5\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "transforms = T.Compose([T.ToTensor(),T.Pad(2),lambda x: x- 0.5])\n",
    "\n",
    "train_ds = torchvision.datasets.FashionMNIST(root = './data/train',train = True,download = True,transform = transforms)\n",
    "valid_ds = torchvision.datasets.FashionMNIST(root = './data/valid',train = False,download = True,transform = transforms)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.313574425312\n"
     ]
    }
   ],
   "source": [
    "# Get FID between two batches of real images\n",
    "\n",
    "it = iter(train_dl)\n",
    "real_batch,_ = next(it)\n",
    "real_batch_2,_ = next(it)\n",
    "\n",
    "fid = get_fid(real_batch, real_batch_2)\n",
    "print(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model which was trained on normalized images and using cosine schedule\n",
    "\n",
    "unet_model = UNet2DModel(in_channels=1, out_channels=1, block_out_channels=(32, 64, 128, 256),norm_num_groups=8)\n",
    "model = DDPM_model(unet_model, 0.0001, 0.02, 1000, cosine_schedule=True)\n",
    "model.load_state_dict(torch.load(\"DDPM_cosine_state_dict.pth\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [10:23<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.21688921323997\n"
     ]
    }
   ],
   "source": [
    "# Get FID using DDPM scheduler for 1000 timesteps\n",
    "\n",
    "sched = DDPMScheduler()\n",
    "preds = sample(sched,model,(64,1,32,32))\n",
    "\n",
    "fid = get_fid(real_batch, preds[-1])\n",
    "print(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 333/333 [03:23<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.48139774630687\n"
     ]
    }
   ],
   "source": [
    "# Get FID using DDIM scheduler for 500 timesteps\n",
    "\n",
    "sched = DDIMScheduler(beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
    "sched.set_timesteps(333)\n",
    "preds = sample(sched,model,(64,1,32,32))\n",
    "\n",
    "\n",
    "fid = get_fid(real_batch, preds[-1])\n",
    "print(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:29<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.99068507811174\n"
     ]
    }
   ],
   "source": [
    "# Get FID using DDIM scheduler for 333 timesteps\n",
    "\n",
    "sched = DDIMScheduler(beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
    "sched.set_timesteps(50)\n",
    "preds = sample(sched,model,(64,1,32,32))\n",
    "\n",
    "\n",
    "fid = get_fid(real_batch, preds[-1])\n",
    "print(fid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
